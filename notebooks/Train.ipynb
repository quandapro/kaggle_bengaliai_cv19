{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from efficientnet.keras import *\n",
    "from classification_models.keras import Classifiers\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.utils import *\n",
    "from keras.layers import *\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "from albumentations import *\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "set_random_seed(2020)\n",
    "np.random.seed(2020)\n",
    "\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridMask(DualTransform):\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "\n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        return image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    TRAINING CONFIG\n",
    "'''\n",
    "IMG_SIZE = (128, 128, 1)\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_DATA = '../data/train_images_128x128_raw'\n",
    "data_name = '128x128_raw'\n",
    "test_size=0.15\n",
    "\n",
    "model_name = 'densenet169'\n",
    "weights = None\n",
    "pretrained_weights = '../data/model_weights/densenet169/densenet169_0.9347_128x128_raw.h5'\n",
    "\n",
    "initial_epoch = 7\n",
    "initial_lr = 0.001\n",
    "min_lr = 0.000001\n",
    "no_of_epochs = 100\n",
    "epochs_per_cycle = 100\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "train_gen = Compose([\n",
    "                    ShiftScaleRotate(shift_limit=0.1,\n",
    "                                     scale_limit=0.1,\n",
    "                                     rotate_limit=20,\n",
    "                                     border_mode=cv2.BORDER_CONSTANT,\n",
    "                                     value=0),\n",
    "                    Cutout(num_holes=1, \n",
    "                           max_h_size=IMG_SIZE[0] // 2, \n",
    "                           max_w_size=IMG_SIZE[1] // 2)\n",
    "            ])\n",
    "val_gen = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = 0\n",
    "    if 'efficientnet' not in model_name:\n",
    "        M, _ = Classifiers.get(model_name)\n",
    "        base_model = M(weights=weights, include_top=False, input_shape=IMG_SIZE)\n",
    "    else:\n",
    "        base_model = EfficientNetB0(weights=weights, include_top=False, input_shape=IMG_SIZE)\n",
    "    x = base_model.output\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    o1 = Dense(168, activation='softmax', kernel_initializer='he_normal', name='grapheme')(x)\n",
    "    o2 = Dense(11, activation='softmax', kernel_initializer='he_normal', name='vowel')(x)\n",
    "    o3 = Dense(7, activation='softmax', kernel_initializer='he_normal', name='consonant')(x)\n",
    "    model = Model(inputs=[base_model.input], outputs=[o1,o2,o3])\n",
    "    if pretrained_weights is not None:\n",
    "        model.load_weights(pretrained_weights)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=initial_lr), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=[recall])\n",
    "    return model\n",
    "        \n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return min_lr + (initial_lr - min_lr) * (1 + np.cos(np.pi * (epoch % epochs_per_cycle) / epochs_per_cycle)) / 2\n",
    "\n",
    "def label_smoothing_loss(y_true, y_pred):\n",
    "    return categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, df, list_id, generator=None, batch_size=32):\n",
    "        self.data = self.build_data(df)\n",
    "        self.list_id = list_id\n",
    "        self.generator = generator\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def build_data(self, df):\n",
    "        image_id = df['image_id']\n",
    "        grapheme_root = df['grapheme_root']\n",
    "        vowel_diacritic = df['vowel_diacritic']\n",
    "        consonant_diacritic = df['consonant_diacritic']\n",
    "        data = {}\n",
    "        for i in range(len(image_id)):\n",
    "            data[image_id[i]] = [grapheme_root[i], vowel_diacritic[i], consonant_diacritic[i]]\n",
    "        return data\n",
    "    \n",
    "    def get_data(self, image_id):\n",
    "        image_path = os.path.join(IMAGE_DATA, image_id + '.png')\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.expand_dims(image, axis=2)\n",
    "        label = self.data[image_id]\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_id) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.list_id)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        list_id = self.list_id[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        x = np.empty((len(list_id), *IMG_SIZE), dtype=np.uint8)\n",
    "        y1 = np.zeros((len(list_id), 168), dtype='float32')\n",
    "        y2 = np.zeros((len(list_id), 11), dtype='float32')\n",
    "        y3 = np.zeros((len(list_id), 7), dtype='float32')\n",
    "        for i in range(len(list_id)):\n",
    "            image_id = list_id[i]\n",
    "            image, label = self.get_data(image_id)\n",
    "            if self.generator is not None:\n",
    "                image = self.generator(image=image)['image']\n",
    "            x[i] = image\n",
    "            y1[i, label[0]] = 1\n",
    "            y2[i, label[1]] = 1\n",
    "            y3[i, label[2]] = 1\n",
    "\n",
    "        return x, [y1, y2, y3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = np.asarray(df['image_id'])\n",
    "train_list, val_list = train_test_split(list_id, test_size=test_size, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 8/100\n",
      " - 772s - loss: 0.8059 - grapheme_loss: 0.5053 - vowel_loss: 0.1610 - consonant_loss: 0.1396 - grapheme_recall: 0.8265 - vowel_recall: 0.9375 - consonant_recall: 0.9505 - val_loss: 0.3753 - val_grapheme_loss: 0.2603 - val_vowel_loss: 0.0588 - val_consonant_loss: 0.0562 - val_grapheme_recall: 0.9187 - val_vowel_recall: 0.9838 - val_consonant_recall: 0.9834\n",
      "\n",
      "Epoch 00008: val_grapheme_recall improved from -inf to 0.91868, saving model to ../data/model_weights/densenet169/densenet169_0.9187_128x128_raw.h5\n",
      "Epoch 9/100\n",
      " - 730s - loss: 0.7656 - grapheme_loss: 0.4778 - vowel_loss: 0.1558 - consonant_loss: 0.1320 - grapheme_recall: 0.8341 - vowel_recall: 0.9393 - consonant_recall: 0.9528 - val_loss: 0.2930 - val_grapheme_loss: 0.1847 - val_vowel_loss: 0.0525 - val_consonant_loss: 0.0557 - val_grapheme_recall: 0.9413 - val_vowel_recall: 0.9857 - val_consonant_recall: 0.9838\n",
      "\n",
      "Epoch 00009: val_grapheme_recall improved from 0.91868 to 0.94126, saving model to ../data/model_weights/densenet169/densenet169_0.9413_128x128_raw.h5\n",
      "Epoch 10/100\n",
      " - 732s - loss: 0.7384 - grapheme_loss: 0.4598 - vowel_loss: 0.1496 - consonant_loss: 0.1290 - grapheme_recall: 0.8402 - vowel_recall: 0.9414 - consonant_recall: 0.9535 - val_loss: 0.2863 - val_grapheme_loss: 0.1724 - val_vowel_loss: 0.0579 - val_consonant_loss: 0.0560 - val_grapheme_recall: 0.9465 - val_vowel_recall: 0.9832 - val_consonant_recall: 0.9836\n",
      "\n",
      "Epoch 00010: val_grapheme_recall improved from 0.94126 to 0.94648, saving model to ../data/model_weights/densenet169/densenet169_0.9465_128x128_raw.h5\n",
      "Epoch 11/100\n",
      " - 731s - loss: 0.7036 - grapheme_loss: 0.4375 - vowel_loss: 0.1422 - consonant_loss: 0.1239 - grapheme_recall: 0.8467 - vowel_recall: 0.9448 - consonant_recall: 0.9557 - val_loss: 0.2926 - val_grapheme_loss: 0.1857 - val_vowel_loss: 0.0495 - val_consonant_loss: 0.0574 - val_grapheme_recall: 0.9416 - val_vowel_recall: 0.9875 - val_consonant_recall: 0.9812\n",
      "\n",
      "Epoch 00011: val_grapheme_recall did not improve from 0.94648\n",
      "Epoch 12/100\n",
      " - 731s - loss: 0.6899 - grapheme_loss: 0.4284 - vowel_loss: 0.1411 - consonant_loss: 0.1204 - grapheme_recall: 0.8505 - vowel_recall: 0.9435 - consonant_recall: 0.9563 - val_loss: 0.2668 - val_grapheme_loss: 0.1676 - val_vowel_loss: 0.0462 - val_consonant_loss: 0.0529 - val_grapheme_recall: 0.9472 - val_vowel_recall: 0.9877 - val_consonant_recall: 0.9847\n",
      "\n",
      "Epoch 00012: val_grapheme_recall improved from 0.94648 to 0.94717, saving model to ../data/model_weights/densenet169/densenet169_0.9472_128x128_raw.h5\n",
      "Epoch 13/100\n",
      " - 731s - loss: 0.6671 - grapheme_loss: 0.4153 - vowel_loss: 0.1362 - consonant_loss: 0.1156 - grapheme_recall: 0.8556 - vowel_recall: 0.9458 - consonant_recall: 0.9585 - val_loss: 0.2371 - val_grapheme_loss: 0.1483 - val_vowel_loss: 0.0395 - val_consonant_loss: 0.0493 - val_grapheme_recall: 0.9509 - val_vowel_recall: 0.9889 - val_consonant_recall: 0.9854\n",
      "\n",
      "Epoch 00013: val_grapheme_recall improved from 0.94717 to 0.95093, saving model to ../data/model_weights/densenet169/densenet169_0.9509_128x128_raw.h5\n",
      "Epoch 14/100\n",
      " - 732s - loss: 0.6474 - grapheme_loss: 0.4027 - vowel_loss: 0.1315 - consonant_loss: 0.1131 - grapheme_recall: 0.8588 - vowel_recall: 0.9475 - consonant_recall: 0.9594 - val_loss: 0.2536 - val_grapheme_loss: 0.1601 - val_vowel_loss: 0.0449 - val_consonant_loss: 0.0487 - val_grapheme_recall: 0.9542 - val_vowel_recall: 0.9877 - val_consonant_recall: 0.9868\n",
      "\n",
      "Epoch 00014: val_grapheme_recall improved from 0.95093 to 0.95422, saving model to ../data/model_weights/densenet169/densenet169_0.9542_128x128_raw.h5\n",
      "Epoch 15/100\n",
      " - 741s - loss: 0.6391 - grapheme_loss: 0.3979 - vowel_loss: 0.1303 - consonant_loss: 0.1110 - grapheme_recall: 0.8602 - vowel_recall: 0.9483 - consonant_recall: 0.9598 - val_loss: 0.2330 - val_grapheme_loss: 0.1380 - val_vowel_loss: 0.0468 - val_consonant_loss: 0.0483 - val_grapheme_recall: 0.9581 - val_vowel_recall: 0.9865 - val_consonant_recall: 0.9860\n",
      "\n",
      "Epoch 00015: val_grapheme_recall improved from 0.95422 to 0.95811, saving model to ../data/model_weights/densenet169/densenet169_0.9581_128x128_raw.h5\n",
      "Epoch 16/100\n",
      " - 738s - loss: 0.6096 - grapheme_loss: 0.3794 - vowel_loss: 0.1237 - consonant_loss: 0.1065 - grapheme_recall: 0.8666 - vowel_recall: 0.9507 - consonant_recall: 0.9611 - val_loss: 0.2248 - val_grapheme_loss: 0.1413 - val_vowel_loss: 0.0385 - val_consonant_loss: 0.0450 - val_grapheme_recall: 0.9571 - val_vowel_recall: 0.9897 - val_consonant_recall: 0.9871\n",
      "\n",
      "Epoch 00016: val_grapheme_recall did not improve from 0.95811\n",
      "Epoch 17/100\n",
      " - 744s - loss: 0.5974 - grapheme_loss: 0.3716 - vowel_loss: 0.1222 - consonant_loss: 0.1036 - grapheme_recall: 0.8689 - vowel_recall: 0.9513 - consonant_recall: 0.9623 - val_loss: 0.2294 - val_grapheme_loss: 0.1416 - val_vowel_loss: 0.0412 - val_consonant_loss: 0.0467 - val_grapheme_recall: 0.9556 - val_vowel_recall: 0.9887 - val_consonant_recall: 0.9860\n",
      "\n",
      "Epoch 00017: val_grapheme_recall did not improve from 0.95811\n",
      "Epoch 18/100\n",
      " - 734s - loss: 0.5858 - grapheme_loss: 0.3640 - vowel_loss: 0.1203 - consonant_loss: 0.1015 - grapheme_recall: 0.8718 - vowel_recall: 0.9514 - consonant_recall: 0.9628 - val_loss: 0.2286 - val_grapheme_loss: 0.1367 - val_vowel_loss: 0.0440 - val_consonant_loss: 0.0480 - val_grapheme_recall: 0.9577 - val_vowel_recall: 0.9876 - val_consonant_recall: 0.9863\n",
      "\n",
      "Epoch 00018: val_grapheme_recall did not improve from 0.95811\n",
      "Epoch 19/100\n",
      " - 731s - loss: 0.5707 - grapheme_loss: 0.3555 - vowel_loss: 0.1166 - consonant_loss: 0.0987 - grapheme_recall: 0.8749 - vowel_recall: 0.9534 - consonant_recall: 0.9640 - val_loss: 0.2304 - val_grapheme_loss: 0.1418 - val_vowel_loss: 0.0428 - val_consonant_loss: 0.0458 - val_grapheme_recall: 0.9569 - val_vowel_recall: 0.9878 - val_consonant_recall: 0.9863\n",
      "\n",
      "Epoch 00019: val_grapheme_recall did not improve from 0.95811\n",
      "Epoch 20/100\n",
      " - 731s - loss: 0.5641 - grapheme_loss: 0.3501 - vowel_loss: 0.1154 - consonant_loss: 0.0986 - grapheme_recall: 0.8757 - vowel_recall: 0.9540 - consonant_recall: 0.9636 - val_loss: 0.2104 - val_grapheme_loss: 0.1279 - val_vowel_loss: 0.0394 - val_consonant_loss: 0.0430 - val_grapheme_recall: 0.9630 - val_vowel_recall: 0.9898 - val_consonant_recall: 0.9875\n",
      "\n",
      "Epoch 00020: val_grapheme_recall improved from 0.95811 to 0.96297, saving model to ../data/model_weights/densenet169/densenet169_0.9630_128x128_raw.h5\n",
      "Epoch 21/100\n",
      " - 731s - loss: 0.5522 - grapheme_loss: 0.3415 - vowel_loss: 0.1128 - consonant_loss: 0.0980 - grapheme_recall: 0.8783 - vowel_recall: 0.9553 - consonant_recall: 0.9642 - val_loss: 0.2009 - val_grapheme_loss: 0.1226 - val_vowel_loss: 0.0364 - val_consonant_loss: 0.0418 - val_grapheme_recall: 0.9642 - val_vowel_recall: 0.9901 - val_consonant_recall: 0.9888\n",
      "\n",
      "Epoch 00021: val_grapheme_recall improved from 0.96297 to 0.96423, saving model to ../data/model_weights/densenet169/densenet169_0.9642_128x128_raw.h5\n",
      "Epoch 22/100\n",
      " - 731s - loss: 0.5359 - grapheme_loss: 0.3320 - vowel_loss: 0.1102 - consonant_loss: 0.0937 - grapheme_recall: 0.8822 - vowel_recall: 0.9557 - consonant_recall: 0.9653 - val_loss: 0.2122 - val_grapheme_loss: 0.1293 - val_vowel_loss: 0.0397 - val_consonant_loss: 0.0433 - val_grapheme_recall: 0.9625 - val_vowel_recall: 0.9899 - val_consonant_recall: 0.9881\n",
      "\n",
      "Epoch 00022: val_grapheme_recall did not improve from 0.96423\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 731s - loss: 0.5300 - grapheme_loss: 0.3309 - vowel_loss: 0.1077 - consonant_loss: 0.0914 - grapheme_recall: 0.8822 - vowel_recall: 0.9566 - consonant_recall: 0.9665 - val_loss: 0.1952 - val_grapheme_loss: 0.1212 - val_vowel_loss: 0.0346 - val_consonant_loss: 0.0394 - val_grapheme_recall: 0.9639 - val_vowel_recall: 0.9911 - val_consonant_recall: 0.9894\n",
      "\n",
      "Epoch 00023: val_grapheme_recall did not improve from 0.96423\n",
      "Epoch 24/100\n",
      " - 731s - loss: 0.5173 - grapheme_loss: 0.3209 - vowel_loss: 0.1061 - consonant_loss: 0.0903 - grapheme_recall: 0.8859 - vowel_recall: 0.9571 - consonant_recall: 0.9670 - val_loss: 0.1919 - val_grapheme_loss: 0.1156 - val_vowel_loss: 0.0367 - val_consonant_loss: 0.0396 - val_grapheme_recall: 0.9658 - val_vowel_recall: 0.9903 - val_consonant_recall: 0.9891\n",
      "\n",
      "Epoch 00024: val_grapheme_recall improved from 0.96423 to 0.96579, saving model to ../data/model_weights/densenet169/densenet169_0.9658_128x128_raw.h5\n",
      "Epoch 25/100\n",
      " - 732s - loss: 0.5163 - grapheme_loss: 0.3202 - vowel_loss: 0.1054 - consonant_loss: 0.0908 - grapheme_recall: 0.8864 - vowel_recall: 0.9573 - consonant_recall: 0.9667 - val_loss: 0.1849 - val_grapheme_loss: 0.1139 - val_vowel_loss: 0.0334 - val_consonant_loss: 0.0376 - val_grapheme_recall: 0.9683 - val_vowel_recall: 0.9906 - val_consonant_recall: 0.9894\n",
      "\n",
      "Epoch 00025: val_grapheme_recall improved from 0.96579 to 0.96832, saving model to ../data/model_weights/densenet169/densenet169_0.9683_128x128_raw.h5\n",
      "Epoch 26/100\n",
      " - 748s - loss: 0.5040 - grapheme_loss: 0.3122 - vowel_loss: 0.1028 - consonant_loss: 0.0889 - grapheme_recall: 0.8897 - vowel_recall: 0.9583 - consonant_recall: 0.9673 - val_loss: 0.1888 - val_grapheme_loss: 0.1161 - val_vowel_loss: 0.0334 - val_consonant_loss: 0.0392 - val_grapheme_recall: 0.9683 - val_vowel_recall: 0.9914 - val_consonant_recall: 0.9897\n",
      "\n",
      "Epoch 00026: val_grapheme_recall did not improve from 0.96832\n",
      "Epoch 27/100\n",
      " - 761s - loss: 0.4910 - grapheme_loss: 0.3031 - vowel_loss: 0.1019 - consonant_loss: 0.0860 - grapheme_recall: 0.8913 - vowel_recall: 0.9589 - consonant_recall: 0.9685 - val_loss: 0.1863 - val_grapheme_loss: 0.1123 - val_vowel_loss: 0.0356 - val_consonant_loss: 0.0385 - val_grapheme_recall: 0.9690 - val_vowel_recall: 0.9914 - val_consonant_recall: 0.9896\n",
      "\n",
      "Epoch 00027: val_grapheme_recall improved from 0.96832 to 0.96902, saving model to ../data/model_weights/densenet169/densenet169_0.9690_128x128_raw.h5\n",
      "Epoch 28/100\n",
      " - 759s - loss: 0.4814 - grapheme_loss: 0.2981 - vowel_loss: 0.0994 - consonant_loss: 0.0838 - grapheme_recall: 0.8935 - vowel_recall: 0.9599 - consonant_recall: 0.9690 - val_loss: 0.1799 - val_grapheme_loss: 0.1096 - val_vowel_loss: 0.0342 - val_consonant_loss: 0.0361 - val_grapheme_recall: 0.9673 - val_vowel_recall: 0.9910 - val_consonant_recall: 0.9895\n",
      "\n",
      "Epoch 00028: val_grapheme_recall did not improve from 0.96902\n",
      "Epoch 29/100\n",
      " - 739s - loss: 0.4852 - grapheme_loss: 0.3000 - vowel_loss: 0.1002 - consonant_loss: 0.0851 - grapheme_recall: 0.8930 - vowel_recall: 0.9592 - consonant_recall: 0.9686 - val_loss: 0.1796 - val_grapheme_loss: 0.1085 - val_vowel_loss: 0.0331 - val_consonant_loss: 0.0381 - val_grapheme_recall: 0.9702 - val_vowel_recall: 0.9921 - val_consonant_recall: 0.9897\n",
      "\n",
      "Epoch 00029: val_grapheme_recall improved from 0.96902 to 0.97018, saving model to ../data/model_weights/densenet169/densenet169_0.9702_128x128_raw.h5\n",
      "Epoch 30/100\n",
      " - 731s - loss: 0.4764 - grapheme_loss: 0.2947 - vowel_loss: 0.0976 - consonant_loss: 0.0841 - grapheme_recall: 0.8947 - vowel_recall: 0.9601 - consonant_recall: 0.9687 - val_loss: 0.1685 - val_grapheme_loss: 0.1008 - val_vowel_loss: 0.0309 - val_consonant_loss: 0.0368 - val_grapheme_recall: 0.9705 - val_vowel_recall: 0.9918 - val_consonant_recall: 0.9900\n",
      "\n",
      "Epoch 00030: val_grapheme_recall improved from 0.97018 to 0.97055, saving model to ../data/model_weights/densenet169/densenet169_0.9705_128x128_raw.h5\n",
      "Epoch 31/100\n",
      " - 731s - loss: 0.4604 - grapheme_loss: 0.2832 - vowel_loss: 0.0971 - consonant_loss: 0.0801 - grapheme_recall: 0.8986 - vowel_recall: 0.9598 - consonant_recall: 0.9701 - val_loss: 0.1733 - val_grapheme_loss: 0.1067 - val_vowel_loss: 0.0309 - val_consonant_loss: 0.0357 - val_grapheme_recall: 0.9691 - val_vowel_recall: 0.9913 - val_consonant_recall: 0.9902\n",
      "\n",
      "Epoch 00031: val_grapheme_recall did not improve from 0.97055\n",
      "Epoch 32/100\n",
      " - 732s - loss: 0.4613 - grapheme_loss: 0.2859 - vowel_loss: 0.0943 - consonant_loss: 0.0811 - grapheme_recall: 0.8980 - vowel_recall: 0.9619 - consonant_recall: 0.9699 - val_loss: 0.1769 - val_grapheme_loss: 0.1070 - val_vowel_loss: 0.0345 - val_consonant_loss: 0.0355 - val_grapheme_recall: 0.9709 - val_vowel_recall: 0.9914 - val_consonant_recall: 0.9907\n",
      "\n",
      "Epoch 00032: val_grapheme_recall improved from 0.97055 to 0.97091, saving model to ../data/model_weights/densenet169/densenet169_0.9709_128x128_raw.h5\n",
      "Epoch 33/100\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ReduceLROnPlateau(monitor='val_grapheme_recall', \n",
    "                                            factor=0.5, \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            mode='max', \n",
    "                                            min_delta=0.001, \n",
    "                                            cooldown=0, \n",
    "                                            min_lr=min_lr),\n",
    "             keras.callbacks.ModelCheckpoint('../data/model_weights/' + model_name + '/' + model_name + '_{val_grapheme_recall:.4f}_' + data_name + '.h5',\n",
    "                                         monitor='val_grapheme_recall', \n",
    "                                         verbose=1, \n",
    "                                         save_best_only=True, \n",
    "                                         save_weights_only=True, \n",
    "                                         mode='max', \n",
    "                                         period=1),\n",
    "            keras.callbacks.CSVLogger('{}_{}.csv'.format(model_name, data_name))]\n",
    "\n",
    "train_datagen = DataGenerator(df, train_list, generator=train_gen, batch_size=BATCH_SIZE)\n",
    "valid_datagen = DataGenerator(df, val_list, generator=val_gen, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = build_model()\n",
    "model.fit_generator(train_datagen,\n",
    "                    steps_per_epoch=len(train_datagen),\n",
    "                    epochs=no_of_epochs,\n",
    "                    validation_data=valid_datagen,\n",
    "                    validation_steps=len(valid_datagen),\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
