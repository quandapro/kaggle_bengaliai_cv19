{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# from efficientnet.keras import *\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.utils import *\n",
    "from keras.layers import *\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "set_random_seed(2020)\n",
    "np.random.seed(2020)\n",
    "\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "DATA_PATH = '../data'\n",
    "CHECKPOINT = '../data/model_weights/mobilenetv2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img,tol=10):\n",
    "    mask = img>tol\n",
    "    return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "def resize(img):\n",
    "    return cv2.resize(img.astype(np.uint8), (IMG_SIZE, IMG_SIZE))\n",
    "def preprocessing(train_image):\n",
    "    train_image = 255 - train_image\n",
    "    train_image.resize((137, 236))\n",
    "    train_image = crop_image_from_gray(train_image)\n",
    "    train_image = resize(train_image)\n",
    "    return train_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.x = []\n",
    "        self.y1 = []\n",
    "        self.y2 = []\n",
    "        self.y3 = []\n",
    "        \n",
    "    def get_data(self):\n",
    "        files = os.listdir(DATA_PATH)\n",
    "        train_csv = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "        train_parquet = []\n",
    "        for file in files:\n",
    "            if 'train_image' in file:\n",
    "                train_parquet.append(file)\n",
    "        \n",
    "        for file in tqdm_notebook(train_parquet, desc='train_parquet'):\n",
    "            parquet = pd.read_parquet(os.path.join(DATA_PATH, file))\n",
    "            for i in tnrange(len(parquet) - 49000, desc='parquet'):\n",
    "                train_image = list(parquet.iloc[3])\n",
    "                image_id = train_image.pop(0)\n",
    "                train_image = np.asarray(train_image)\n",
    "                train_image = preprocessing(train_image)\n",
    "                self.x.append(train_image)\n",
    "                \n",
    "                grapheme_root = train_csv['grapheme_root'][train_csv['image_id'] == image_id]\n",
    "                vowel_diacritic = train_csv['vowel_diacritic'][train_csv['image_id'] == image_id]\n",
    "                consonant_diacritic = train_csv['consonant_diacritic'][train_csv['image_id'] == image_id]\n",
    "                \n",
    "                self.y1.append(int(grapheme_root))\n",
    "                self.y2.append(int(vowel_diacritic))\n",
    "                self.y3.append(int(consonant_diacritic))     \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel:\n",
    "    def __init__(self):\n",
    "        self.model = self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        base_model = keras.applications.MobileNetV2(weights=None, include_top=False, input_shape=(IMG_SIZE,IMG_SIZE,1))\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        o1 = Dense(168, activation='softmax', kernel_initializer='he_normal', name='grapheme')(x)\n",
    "        o2 = Dense(11, activation='softmax', kernel_initializer='he_normal', name='vowel')(x)\n",
    "        o3 = Dense(7, activation='softmax', kernel_initializer='he_normal', name='consonant')(x)\n",
    "        return Model(inputs=[base_model.input], outputs=[o1,o2,o3])\n",
    "        \n",
    "    def load_weight(self, model_weight_path):\n",
    "        self.model.load_weights(model_weight_path)\n",
    "        \n",
    "    def fit_dataset(self, dataset, epochs=20, callbacks=None):\n",
    "        x = np.asarray(dataset.x, dtype='float32')\n",
    "        x = x.reshape((1210, 64, 64, 1))\n",
    "        [y1, y2, y3] = [np.asarray(dataset.y1, dtype='float32'), np.asarray(dataset.y2, dtype='float32'), np.asarray(dataset.y3, dtype='float32')]\n",
    "        \n",
    "        self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "        self.model.fit(x, [y1, y2, y3],\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=epochs,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint(CHECKPOINT, \n",
    "                                             monitor='loss', \n",
    "                                             verbose=0, \n",
    "                                             save_best_only=False, \n",
    "                                             save_weights_only=False, \n",
    "                                             mode='auto', \n",
    "                                             period=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationModel()\n",
    "model.fit_dataset(dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
