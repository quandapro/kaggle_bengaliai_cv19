{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from efficientnet.keras import *\n",
    "from classification_models.keras import Classifiers\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.utils import *\n",
    "from keras.layers import *\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "from albumentations import *\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "set_random_seed(2020)\n",
    "np.random.seed(2020)\n",
    "\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    TRAINING CONFIG\n",
    "'''\n",
    "IMG_SIZE = (64, 64, 1)\n",
    "BATCH_SIZE = 256\n",
    "IMAGE_DATA = '../data/train_images_64x64_raw'\n",
    "data_name = '64x64_mixup'\n",
    "test_size=0.15\n",
    "\n",
    "model_name = 'resnet18'\n",
    "weights = None\n",
    "pretrained_weights = None\n",
    "\n",
    "initial_epoch = 0\n",
    "initial_lr = 0.001\n",
    "min_lr = 0.00001\n",
    "MODE = 'training'\n",
    "no_of_epochs = 100\n",
    "epochs_per_cycle = 100\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# train_gen = Compose([\n",
    "#                     ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=20),\n",
    "#                     Cutout(num_holes=1, \n",
    "#                            max_h_size=IMG_SIZE[0] // 2, \n",
    "#                            max_w_size=IMG_SIZE[1] // 2),\n",
    "#             ])\n",
    "train_gen = None\n",
    "val_gen = None\n",
    "\n",
    "CUTMIX = True\n",
    "MIXUP = False\n",
    "ALPHA = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return min_lr + (initial_lr - min_lr) * (1 + np.cos(np.pi * (epoch % epochs_per_cycle) / epochs_per_cycle)) / 2\n",
    "\n",
    "def build_model():\n",
    "    base_model = 0\n",
    "    if 'efficientnet' not in model_name:\n",
    "        M, _ = Classifiers.get(model_name)\n",
    "        base_model = M(weights=weights, include_top=False, input_shape=IMG_SIZE)\n",
    "    else:\n",
    "        base_model = EfficientNetB0(weights=weights, include_top=False, input_shape=IMG_SIZE)\n",
    "    x = base_model.output\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    o1 = Dense(168, activation='softmax', kernel_initializer='he_normal', name='grapheme')(x)\n",
    "    o2 = Dense(11, activation='softmax', kernel_initializer='he_normal', name='vowel')(x)\n",
    "    o3 = Dense(7, activation='softmax', kernel_initializer='he_normal', name='consonant')(x)\n",
    "    model = Model(inputs=[base_model.input], outputs=[o1,o2,o3])\n",
    "    if pretrained_weights is not None:\n",
    "        model.load_weights(pretrained_weights)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=initial_lr), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=[recall])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, df, list_id, generator=None, batch_size=32, \n",
    "                 use_mixup=False, alpha=0.2, \n",
    "                 use_cutmix=False):\n",
    "        self.data = self.build_data(df)\n",
    "        self.list_id = list_id\n",
    "        self.generator = generator\n",
    "        self.batch_size = batch_size\n",
    "        self.use_mixup = use_mixup\n",
    "        self.use_cutmix = use_cutmix\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def build_data(self, df):\n",
    "        image_id = df['image_id']\n",
    "        grapheme_root = df['grapheme_root']\n",
    "        vowel_diacritic = df['vowel_diacritic']\n",
    "        consonant_diacritic = df['consonant_diacritic']\n",
    "        data = {}\n",
    "        for i in range(len(image_id)):\n",
    "            data[image_id[i]] = [grapheme_root[i], vowel_diacritic[i], consonant_diacritic[i]]\n",
    "        return data\n",
    "    \n",
    "    def get_data_by_id(self, image_id):\n",
    "        image_path = os.path.join(IMAGE_DATA, image_id + '.png')\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.expand_dims(image, axis=2)\n",
    "        label = self.data[image_id]\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_id) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.list_id)\n",
    "    \n",
    "    def mixup(self, x, y1, y2, y3):\n",
    "        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n",
    "        x_l = l.reshape(self.batch_size, 1, 1, 1)\n",
    "        y_l = l.reshape(self.batch_size, 1)\n",
    "        x_t, y1_t, y2_t, y3_t = shuffle(x, y1, y2, y3)\n",
    "\n",
    "        X = x * x_l + x_t * (1 - x_l)\n",
    "        Y1 = y1 * y_l + y1_t * (1 - y_l)\n",
    "        Y2 = y2 * y_l + y2_t * (1 - y_l)\n",
    "        Y3 = y3 * y_l + y3_t * (1 - y_l)\n",
    "        return X, Y1, Y2, Y3\n",
    "    \n",
    "    def cutmix(self, x, Y_1, Y_2, Y_3):\n",
    "        cut_ratio = np.random.beta(a=1, b=1, size=self.batch_size)\n",
    "        cut_ratio = np.clip(cut_ratio, 0.2, 0.8)\n",
    "        label_ratio = cut_ratio.reshape(self.batch_size, 1)\n",
    "        x_t, y1_t, y2_t, y3_t = shuffle(x, Y_1, Y_2, Y_3)\n",
    "        \n",
    "        cut_img = x_t\n",
    "        X = x\n",
    "        for i in range(self.batch_size):\n",
    "            cut_size = int((IMG_SIZE[0]-1) * cut_ratio[i])\n",
    "            y1 = np.random.randint(0, (IMG_SIZE[0]-1) - cut_size)\n",
    "            x1 = np.random.randint(0, (IMG_SIZE[0]-1) - cut_size)\n",
    "            y2 = y1 + cut_size\n",
    "            x2 = x1 + cut_size\n",
    "            cut_arr = cut_img[i][y1:y2, x1:x2]\n",
    "            cutmix_img = x[i]\n",
    "            cutmix_img[y1:y2, x1:x2] = cut_arr\n",
    "            X[i] = cutmix_img\n",
    "            \n",
    "        Y1 = Y_1 * (1 - (label_ratio ** 2)) + y1_t * (label_ratio ** 2)\n",
    "        Y2 = Y_2 * (1 - (label_ratio ** 2)) + y2_t * (label_ratio ** 2)\n",
    "        Y3 = Y_3 * (1 - (label_ratio ** 2)) + y3_t * (label_ratio ** 2)\n",
    "        return X, Y1, Y2, Y3\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        list_id = self.list_id[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        x = np.empty((len(list_id), *IMG_SIZE), dtype=np.uint8)\n",
    "        y1 = np.zeros((len(list_id), 168), dtype='float32')\n",
    "        y2 = np.zeros((len(list_id), 11), dtype='float32')\n",
    "        y3 = np.zeros((len(list_id), 7), dtype='float32')\n",
    "        for i in range(len(list_id)):\n",
    "            image_id = list_id[i]\n",
    "            image, label = self.get_data_by_id(image_id)\n",
    "            x[i] = image\n",
    "            y1[i, label[0]] = 1\n",
    "            y2[i, label[1]] = 1\n",
    "            y3[i, label[2]] = 1\n",
    "        \n",
    "        if self.use_mixup:\n",
    "            x, y1, y2, y3 = self.mixup(x.astype('float32'), y1, y2, y3)\n",
    "        \n",
    "        if self.use_cutmix:\n",
    "            x, y1, y2, y3 = self.cutmix(x, y1, y2, y3)\n",
    "            \n",
    "        if self.generator is not None:\n",
    "            for i in range(len(list_id)):\n",
    "                x[i] = self.generator(image=x[i])['image']\n",
    "\n",
    "        return x, [y1, y2, y3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = np.asarray(df['image_id'])\n",
    "train_list, val_list = train_test_split(list_id, test_size=test_size, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.LearningRateScheduler(scheduler, verbose=1),\n",
    "             keras.callbacks.ModelCheckpoint('../data/model_weights/' + model_name + '/' + model_name + '_{val_grapheme_recall:.4f}_' + data_name + '.h5',\n",
    "                                         monitor='val_grapheme_recall', \n",
    "                                         verbose=1, \n",
    "                                         save_best_only=True, \n",
    "                                         save_weights_only=True, \n",
    "                                         mode='max', \n",
    "                                         period=1),\n",
    "            keras.callbacks.CSVLogger('stats/{}_{}.csv'.format(model_name, data_name))]\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "666/666 [==============================] - 96s 144ms/step - loss: 6.2961 - grapheme_loss: 3.9927 - vowel_loss: 1.4247 - consonant_loss: 0.8787 - grapheme_recall: 0.0077 - vowel_recall: 0.2830 - consonant_recall: 0.5788 - val_loss: 3.0261 - val_grapheme_loss: 2.0826 - val_vowel_loss: 0.5600 - val_consonant_loss: 0.3835 - val_grapheme_recall: 0.1450 - val_vowel_recall: 0.7508 - val_consonant_recall: 0.8621\n",
      "\n",
      "Epoch 00001: val_grapheme_recall improved from -inf to 0.14503, saving model to ../data/model_weights/resnet18/resnet18_0.1450_64x64_mixup.h5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0009997557473810372.\n",
      "666/666 [==============================] - 64s 96ms/step - loss: 5.1297 - grapheme_loss: 3.1317 - vowel_loss: 1.2458 - consonant_loss: 0.7522 - grapheme_recall: 0.0797 - vowel_recall: 0.3975 - consonant_recall: 0.6538 - val_loss: 2.0859 - val_grapheme_loss: 1.3394 - val_vowel_loss: 0.4435 - val_consonant_loss: 0.3031 - val_grapheme_recall: 0.3455 - val_vowel_recall: 0.8520 - val_consonant_recall: 0.9136\n",
      "\n",
      "Epoch 00002: val_grapheme_recall improved from 0.14503 to 0.34549, saving model to ../data/model_weights/resnet18/resnet18_0.3455_64x64_mixup.h5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0009990232305719944.\n",
      "666/666 [==============================] - 64s 96ms/step - loss: 4.7847 - grapheme_loss: 2.8783 - vowel_loss: 1.1873 - consonant_loss: 0.7190 - grapheme_recall: 0.1489 - vowel_recall: 0.4364 - consonant_recall: 0.6712 - val_loss: 1.8398 - val_grapheme_loss: 1.1291 - val_vowel_loss: 0.4012 - val_consonant_loss: 0.3095 - val_grapheme_recall: 0.4677 - val_vowel_recall: 0.8774 - val_consonant_recall: 0.9148\n",
      "\n",
      "Epoch 00003: val_grapheme_recall improved from 0.34549 to 0.46772, saving model to ../data/model_weights/resnet18/resnet18_0.4677_64x64_mixup.h5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0009978031724785245.\n",
      "666/666 [==============================] - 64s 96ms/step - loss: 4.6032 - grapheme_loss: 2.7478 - vowel_loss: 1.1549 - consonant_loss: 0.7005 - grapheme_recall: 0.1903 - vowel_recall: 0.4541 - consonant_recall: 0.6801 - val_loss: 1.4257 - val_grapheme_loss: 0.8556 - val_vowel_loss: 0.3288 - val_consonant_loss: 0.2413 - val_grapheme_recall: 0.6110 - val_vowel_recall: 0.9137 - val_consonant_recall: 0.9468\n",
      "\n",
      "Epoch 00004: val_grapheme_recall improved from 0.46772 to 0.61098, saving model to ../data/model_weights/resnet18/resnet18_0.6110_64x64_mixup.h5\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009960967771506667.\n",
      "666/666 [==============================] - 60s 90ms/step - loss: 4.4760 - grapheme_loss: 2.6622 - vowel_loss: 1.1279 - consonant_loss: 0.6858 - grapheme_recall: 0.2171 - vowel_recall: 0.4705 - consonant_recall: 0.6873 - val_loss: 1.2385 - val_grapheme_loss: 0.7932 - val_vowel_loss: 0.2453 - val_consonant_loss: 0.1999 - val_grapheme_recall: 0.6868 - val_vowel_recall: 0.9390 - val_consonant_recall: 0.9492\n",
      "\n",
      "Epoch 00005: val_grapheme_recall improved from 0.61098 to 0.68677, saving model to ../data/model_weights/resnet18/resnet18_0.6868_64x64_mixup.h5\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009939057285945933.\n",
      "666/666 [==============================] - 57s 86ms/step - loss: 4.3752 - grapheme_loss: 2.5963 - vowel_loss: 1.1047 - consonant_loss: 0.6742 - grapheme_recall: 0.2401 - vowel_recall: 0.4803 - consonant_recall: 0.6937 - val_loss: 1.1335 - val_grapheme_loss: 0.6814 - val_vowel_loss: 0.2352 - val_consonant_loss: 0.2169 - val_grapheme_recall: 0.7281 - val_vowel_recall: 0.9428 - val_consonant_recall: 0.9420\n",
      "\n",
      "Epoch 00006: val_grapheme_recall improved from 0.68677 to 0.72813, saving model to ../data/model_weights/resnet18/resnet18_0.7281_64x64_mixup.h5\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.000991232189110701.\n",
      "666/666 [==============================] - 60s 90ms/step - loss: 4.2791 - grapheme_loss: 2.5353 - vowel_loss: 1.0816 - consonant_loss: 0.6622 - grapheme_recall: 0.2564 - vowel_recall: 0.4888 - consonant_recall: 0.6977 - val_loss: 1.0271 - val_grapheme_loss: 0.6115 - val_vowel_loss: 0.2362 - val_consonant_loss: 0.1794 - val_grapheme_recall: 0.7610 - val_vowel_recall: 0.9499 - val_consonant_recall: 0.9599\n",
      "\n",
      "Epoch 00007: val_grapheme_recall improved from 0.72813 to 0.76098, saving model to ../data/model_weights/resnet18/resnet18_0.7610_64x64_mixup.h5\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.00098807879715968.\n",
      "666/666 [==============================] - 59s 88ms/step - loss: 4.2028 - grapheme_loss: 2.4856 - vowel_loss: 1.0643 - consonant_loss: 0.6529 - grapheme_recall: 0.2700 - vowel_recall: 0.4952 - consonant_recall: 0.7013 - val_loss: 0.9915 - val_grapheme_loss: 0.5841 - val_vowel_loss: 0.2287 - val_consonant_loss: 0.1787 - val_grapheme_recall: 0.7801 - val_vowel_recall: 0.9490 - val_consonant_recall: 0.9593\n",
      "\n",
      "Epoch 00008: val_grapheme_recall improved from 0.76098 to 0.78011, saving model to ../data/model_weights/resnet18/resnet18_0.7801_64x64_mixup.h5\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009844486647586723.\n",
      "666/666 [==============================] - 58s 86ms/step - loss: 4.1347 - grapheme_loss: 2.4433 - vowel_loss: 1.0472 - consonant_loss: 0.6442 - grapheme_recall: 0.2814 - vowel_recall: 0.5010 - consonant_recall: 0.7037 - val_loss: 0.9829 - val_grapheme_loss: 0.5575 - val_vowel_loss: 0.2393 - val_consonant_loss: 0.1862 - val_grapheme_recall: 0.7900 - val_vowel_recall: 0.9458 - val_consonant_recall: 0.9587\n",
      "\n",
      "Epoch 00009: val_grapheme_recall improved from 0.78011 to 0.79003, saving model to ../data/model_weights/resnet18/resnet18_0.7900_64x64_mixup.h5\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009803453744100868.\n",
      "666/666 [==============================] - 59s 89ms/step - loss: 4.0660 - grapheme_loss: 2.3990 - vowel_loss: 1.0306 - consonant_loss: 0.6365 - grapheme_recall: 0.2907 - vowel_recall: 0.5044 - consonant_recall: 0.7076 - val_loss: 0.8166 - val_grapheme_loss: 0.4831 - val_vowel_loss: 0.1827 - val_consonant_loss: 0.1508 - val_grapheme_recall: 0.8275 - val_vowel_recall: 0.9640 - val_consonant_recall: 0.9689\n",
      "\n",
      "Epoch 00010: val_grapheme_recall improved from 0.79003 to 0.82749, saving model to ../data/model_weights/resnet18/resnet18_0.8275_64x64_mixup.h5\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009757729755661011.\n",
      "666/666 [==============================] - 57s 86ms/step - loss: 4.0112 - grapheme_loss: 2.3633 - vowel_loss: 1.0202 - consonant_loss: 0.6276 - grapheme_recall: 0.3003 - vowel_recall: 0.5076 - consonant_recall: 0.7104 - val_loss: 1.0680 - val_grapheme_loss: 0.6073 - val_vowel_loss: 0.2702 - val_consonant_loss: 0.1904 - val_grapheme_recall: 0.7663 - val_vowel_recall: 0.9542 - val_consonant_recall: 0.9648\n",
      "\n",
      "Epoch 00011: val_grapheme_recall did not improve from 0.82749\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009707359806323416.\n",
      "666/666 [==============================] - 59s 89ms/step - loss: 3.9652 - grapheme_loss: 2.3321 - vowel_loss: 1.0099 - consonant_loss: 0.6232 - grapheme_recall: 0.3089 - vowel_recall: 0.5096 - consonant_recall: 0.7108 - val_loss: 0.6955 - val_grapheme_loss: 0.4198 - val_vowel_loss: 0.1488 - val_consonant_loss: 0.1270 - val_grapheme_recall: 0.8543 - val_vowel_recall: 0.9705 - val_consonant_recall: 0.9711\n",
      "\n",
      "Epoch 00012: val_grapheme_recall improved from 0.82749 to 0.85430, saving model to ../data/model_weights/resnet18/resnet18_0.8543_64x64_mixup.h5\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009652393605146844.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 63s 95ms/step - loss: 3.9378 - grapheme_loss: 2.3121 - vowel_loss: 1.0064 - consonant_loss: 0.6192 - grapheme_recall: 0.3110 - vowel_recall: 0.5077 - consonant_recall: 0.7122 - val_loss: 0.6506 - val_grapheme_loss: 0.3944 - val_vowel_loss: 0.1402 - val_consonant_loss: 0.1160 - val_grapheme_recall: 0.8669 - val_vowel_recall: 0.9717 - val_consonant_recall: 0.9735\n",
      "\n",
      "Epoch 00013: val_grapheme_recall improved from 0.85430 to 0.86685, saving model to ../data/model_weights/resnet18/resnet18_0.8669_64x64_mixup.h5\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009592885397135706.\n",
      "666/666 [==============================] - 61s 92ms/step - loss: 3.8923 - grapheme_loss: 2.2853 - vowel_loss: 0.9929 - consonant_loss: 0.6141 - grapheme_recall: 0.3180 - vowel_recall: 0.5130 - consonant_recall: 0.7133 - val_loss: 0.8155 - val_grapheme_loss: 0.4699 - val_vowel_loss: 0.1891 - val_consonant_loss: 0.1565 - val_grapheme_recall: 0.8423 - val_vowel_recall: 0.9674 - val_consonant_recall: 0.9667\n",
      "\n",
      "Epoch 00014: val_grapheme_recall did not improve from 0.86685\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009528893909706797.\n",
      "666/666 [==============================] - 60s 90ms/step - loss: 3.8467 - grapheme_loss: 2.2535 - vowel_loss: 0.9843 - consonant_loss: 0.6089 - grapheme_recall: 0.3253 - vowel_recall: 0.5167 - consonant_recall: 0.7154 - val_loss: 0.6289 - val_grapheme_loss: 0.3693 - val_vowel_loss: 0.1375 - val_consonant_loss: 0.1221 - val_grapheme_recall: 0.8773 - val_vowel_recall: 0.9728 - val_consonant_recall: 0.9734\n",
      "\n",
      "Epoch 00015: val_grapheme_recall improved from 0.86685 to 0.87727, saving model to ../data/model_weights/resnet18/resnet18_0.8773_64x64_mixup.h5\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0009460482294732421.\n",
      "666/666 [==============================] - 58s 88ms/step - loss: 3.8123 - grapheme_loss: 2.2317 - vowel_loss: 0.9778 - consonant_loss: 0.6028 - grapheme_recall: 0.3310 - vowel_recall: 0.5183 - consonant_recall: 0.7167 - val_loss: 0.6471 - val_grapheme_loss: 0.3802 - val_vowel_loss: 0.1473 - val_consonant_loss: 0.1196 - val_grapheme_recall: 0.8745 - val_vowel_recall: 0.9709 - val_consonant_recall: 0.9733\n",
      "\n",
      "Epoch 00016: val_grapheme_recall did not improve from 0.87727\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0009387718066217125.\n",
      "666/666 [==============================] - 58s 88ms/step - loss: 3.7894 - grapheme_loss: 2.2148 - vowel_loss: 0.9716 - consonant_loss: 0.6031 - grapheme_recall: 0.3340 - vowel_recall: 0.5195 - consonant_recall: 0.7171 - val_loss: 0.7183 - val_grapheme_loss: 0.4119 - val_vowel_loss: 0.1761 - val_consonant_loss: 0.1304 - val_grapheme_recall: 0.8700 - val_vowel_recall: 0.9702 - val_consonant_recall: 0.9745\n",
      "\n",
      "Epoch 00017: val_grapheme_recall did not improve from 0.87727\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0009310673033669522.\n",
      "666/666 [==============================] - 59s 89ms/step - loss: 3.7611 - grapheme_loss: 2.1956 - vowel_loss: 0.9673 - consonant_loss: 0.5982 - grapheme_recall: 0.3374 - vowel_recall: 0.5211 - consonant_recall: 0.7194 - val_loss: 0.6524 - val_grapheme_loss: 0.3747 - val_vowel_loss: 0.1644 - val_consonant_loss: 0.1134 - val_grapheme_recall: 0.8813 - val_vowel_recall: 0.9654 - val_consonant_recall: 0.9757\n",
      "\n",
      "Epoch 00018: val_grapheme_recall improved from 0.87727 to 0.88131, saving model to ../data/model_weights/resnet18/resnet18_0.8813_64x64_mixup.h5\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0009229423231234975.\n",
      "666/666 [==============================] - 61s 92ms/step - loss: 3.7273 - grapheme_loss: 2.1748 - vowel_loss: 0.9592 - consonant_loss: 0.5934 - grapheme_recall: 0.3439 - vowel_recall: 0.5246 - consonant_recall: 0.7219 - val_loss: 0.6215 - val_grapheme_loss: 0.3556 - val_vowel_loss: 0.1479 - val_consonant_loss: 0.1180 - val_grapheme_recall: 0.8880 - val_vowel_recall: 0.9763 - val_consonant_recall: 0.9764\n",
      "\n",
      "Epoch 00019: val_grapheme_recall improved from 0.88131 to 0.88802, saving model to ../data/model_weights/resnet18/resnet18_0.8880_64x64_mixup.h5\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0009144048842659081.\n",
      "666/666 [==============================] - 59s 88ms/step - loss: 3.7115 - grapheme_loss: 2.1654 - vowel_loss: 0.9555 - consonant_loss: 0.5906 - grapheme_recall: 0.3460 - vowel_recall: 0.5239 - consonant_recall: 0.7213 - val_loss: 0.5894 - val_grapheme_loss: 0.3447 - val_vowel_loss: 0.1351 - val_consonant_loss: 0.1097 - val_grapheme_recall: 0.8896 - val_vowel_recall: 0.9766 - val_consonant_recall: 0.9776\n",
      "\n",
      "Epoch 00020: val_grapheme_recall improved from 0.88802 to 0.88962, saving model to ../data/model_weights/resnet18/resnet18_0.8896_64x64_mixup.h5\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.000905463412215599.\n",
      "666/666 [==============================] - 59s 89ms/step - loss: 3.7041 - grapheme_loss: 2.1612 - vowel_loss: 0.9554 - consonant_loss: 0.5875 - grapheme_recall: 0.3459 - vowel_recall: 0.5213 - consonant_recall: 0.7230 - val_loss: 0.5940 - val_grapheme_loss: 0.3402 - val_vowel_loss: 0.1346 - val_consonant_loss: 0.1191 - val_grapheme_recall: 0.8954 - val_vowel_recall: 0.9778 - val_consonant_recall: 0.9740\n",
      "\n",
      "Epoch 00021: val_grapheme_recall improved from 0.88962 to 0.89543, saving model to ../data/model_weights/resnet18/resnet18_0.8954_64x64_mixup.h5\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008961267311259668.\n",
      "666/666 [==============================] - 64s 96ms/step - loss: 3.6780 - grapheme_loss: 2.1429 - vowel_loss: 0.9483 - consonant_loss: 0.5868 - grapheme_recall: 0.3494 - vowel_recall: 0.5261 - consonant_recall: 0.7222 - val_loss: 0.5982 - val_grapheme_loss: 0.3329 - val_vowel_loss: 0.1501 - val_consonant_loss: 0.1153 - val_grapheme_recall: 0.9000 - val_vowel_recall: 0.9767 - val_consonant_recall: 0.9790\n",
      "\n",
      "Epoch 00022: val_grapheme_recall improved from 0.89543 to 0.89997, saving model to ../data/model_weights/resnet18/resnet18_0.9000_64x64_mixup.h5\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008864040551740157.\n",
      "666/666 [==============================] - 64s 96ms/step - loss: 3.6535 - grapheme_loss: 2.1269 - vowel_loss: 0.9437 - consonant_loss: 0.5829 - grapheme_recall: 0.3529 - vowel_recall: 0.5258 - consonant_recall: 0.7226 - val_loss: 0.5500 - val_grapheme_loss: 0.3176 - val_vowel_loss: 0.1281 - val_consonant_loss: 0.1043 - val_grapheme_recall: 0.9029 - val_vowel_recall: 0.9782 - val_consonant_recall: 0.9791\n",
      "\n",
      "Epoch 00023: val_grapheme_recall improved from 0.89997 to 0.90294, saving model to ../data/model_weights/resnet18/resnet18_0.9029_64x64_mixup.h5\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008763049794670775.\n",
      "666/666 [==============================] - 64s 96ms/step - loss: 3.6337 - grapheme_loss: 2.1140 - vowel_loss: 0.9391 - consonant_loss: 0.5805 - grapheme_recall: 0.3558 - vowel_recall: 0.5268 - consonant_recall: 0.7233 - val_loss: 0.5426 - val_grapheme_loss: 0.3157 - val_vowel_loss: 0.1226 - val_consonant_loss: 0.1043 - val_grapheme_recall: 0.9032 - val_vowel_recall: 0.9786 - val_consonant_recall: 0.9764\n",
      "\n",
      "Epoch 00024: val_grapheme_recall improved from 0.90294 to 0.90325, saving model to ../data/model_weights/resnet18/resnet18_0.9032_64x64_mixup.h5\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0008658394705735987.\n",
      "666/666 [==============================] - 65s 97ms/step - loss: 3.6137 - grapheme_loss: 2.1023 - vowel_loss: 0.9331 - consonant_loss: 0.5783 - grapheme_recall: 0.3591 - vowel_recall: 0.5314 - consonant_recall: 0.7264 - val_loss: 0.5442 - val_grapheme_loss: 0.3172 - val_vowel_loss: 0.1240 - val_consonant_loss: 0.1030 - val_grapheme_recall: 0.9041 - val_vowel_recall: 0.9792 - val_consonant_recall: 0.9798\n",
      "\n",
      "Epoch 00025: val_grapheme_recall improved from 0.90325 to 0.90415, saving model to ../data/model_weights/resnet18/resnet18_0.9041_64x64_mixup.h5\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.000855017856687341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 64s 97ms/step - loss: 3.6072 - grapheme_loss: 2.0978 - vowel_loss: 0.9323 - consonant_loss: 0.5770 - grapheme_recall: 0.3591 - vowel_recall: 0.5270 - consonant_recall: 0.7247 - val_loss: 0.5813 - val_grapheme_loss: 0.3280 - val_vowel_loss: 0.1432 - val_consonant_loss: 0.1102 - val_grapheme_recall: 0.9029 - val_vowel_recall: 0.9789 - val_consonant_recall: 0.9795\n",
      "\n",
      "Epoch 00026: val_grapheme_recall did not improve from 0.90415\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0008438508174347009.\n",
      "666/666 [==============================] - 65s 97ms/step - loss: 3.5831 - grapheme_loss: 2.0808 - vowel_loss: 0.9274 - consonant_loss: 0.5749 - grapheme_recall: 0.3632 - vowel_recall: 0.5303 - consonant_recall: 0.7264 - val_loss: 0.5384 - val_grapheme_loss: 0.3109 - val_vowel_loss: 0.1269 - val_consonant_loss: 0.1006 - val_grapheme_recall: 0.9038 - val_vowel_recall: 0.9780 - val_consonant_recall: 0.9787\n",
      "\n",
      "Epoch 00027: val_grapheme_recall did not improve from 0.90415\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0008323493733352077.\n",
      "666/666 [==============================] - 62s 93ms/step - loss: 3.5784 - grapheme_loss: 2.0763 - vowel_loss: 0.9270 - consonant_loss: 0.5751 - grapheme_recall: 0.3636 - vowel_recall: 0.5288 - consonant_recall: 0.7249 - val_loss: 0.4911 - val_grapheme_loss: 0.2836 - val_vowel_loss: 0.1163 - val_consonant_loss: 0.0913 - val_grapheme_recall: 0.9155 - val_vowel_recall: 0.9806 - val_consonant_recall: 0.9810\n",
      "\n",
      "Epoch 00028: val_grapheme_recall improved from 0.90415 to 0.91546, saving model to ../data/model_weights/resnet18/resnet18_0.9155_64x64_mixup.h5\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0008205248749256015.\n",
      "666/666 [==============================] - 58s 87ms/step - loss: 3.5513 - grapheme_loss: 2.0614 - vowel_loss: 0.9200 - consonant_loss: 0.5699 - grapheme_recall: 0.3671 - vowel_recall: 0.5327 - consonant_recall: 0.7295 - val_loss: 0.4884 - val_grapheme_loss: 0.2831 - val_vowel_loss: 0.1118 - val_consonant_loss: 0.0935 - val_grapheme_recall: 0.9181 - val_vowel_recall: 0.9798 - val_consonant_recall: 0.9806\n",
      "\n",
      "Epoch 00029: val_grapheme_recall improved from 0.91546 to 0.91810, saving model to ../data/model_weights/resnet18/resnet18_0.9181_64x64_mixup.h5\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0008083889915582234.\n",
      "666/666 [==============================] - 58s 88ms/step - loss: 3.5434 - grapheme_loss: 2.0561 - vowel_loss: 0.9190 - consonant_loss: 0.5683 - grapheme_recall: 0.3691 - vowel_recall: 0.5314 - consonant_recall: 0.7274 - val_loss: 0.5780 - val_grapheme_loss: 0.3243 - val_vowel_loss: 0.1467 - val_consonant_loss: 0.1071 - val_grapheme_recall: 0.9037 - val_vowel_recall: 0.9774 - val_consonant_recall: 0.9807\n",
      "\n",
      "Epoch 00030: val_grapheme_recall did not improve from 0.91810\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007959536998847743.\n",
      "666/666 [==============================] - 58s 88ms/step - loss: 3.5268 - grapheme_loss: 2.0445 - vowel_loss: 0.9148 - consonant_loss: 0.5674 - grapheme_recall: 0.3722 - vowel_recall: 0.5348 - consonant_recall: 0.7284 - val_loss: 0.5587 - val_grapheme_loss: 0.3215 - val_vowel_loss: 0.1320 - val_consonant_loss: 0.1051 - val_grapheme_recall: 0.9068 - val_vowel_recall: 0.9801 - val_consonant_recall: 0.9803\n",
      "\n",
      "Epoch 00031: val_grapheme_recall did not improve from 0.91810\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007832312720368048.\n",
      "666/666 [==============================] - 58s 88ms/step - loss: 3.5184 - grapheme_loss: 2.0397 - vowel_loss: 0.9130 - consonant_loss: 0.5658 - grapheme_recall: 0.3719 - vowel_recall: 0.5351 - consonant_recall: 0.7294 - val_loss: 0.5417 - val_grapheme_loss: 0.3039 - val_vowel_loss: 0.1336 - val_consonant_loss: 0.1042 - val_grapheme_recall: 0.9142 - val_vowel_recall: 0.9801 - val_consonant_recall: 0.9807\n",
      "\n",
      "Epoch 00032: val_grapheme_recall did not improve from 0.91810\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007702342635146033.\n",
      "666/666 [==============================] - 60s 91ms/step - loss: 3.5168 - grapheme_loss: 2.0368 - vowel_loss: 0.9131 - consonant_loss: 0.5669 - grapheme_recall: 0.3720 - vowel_recall: 0.5328 - consonant_recall: 0.7276 - val_loss: 0.5881 - val_grapheme_loss: 0.3301 - val_vowel_loss: 0.1446 - val_consonant_loss: 0.1134 - val_grapheme_recall: 0.9077 - val_vowel_recall: 0.9807 - val_consonant_recall: 0.9810\n",
      "\n",
      "Epoch 00033: val_grapheme_recall did not improve from 0.91810\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007569755007964338.\n",
      "666/666 [==============================] - 64s 96ms/step - loss: 3.4952 - grapheme_loss: 2.0232 - vowel_loss: 0.9087 - consonant_loss: 0.5633 - grapheme_recall: 0.3754 - vowel_recall: 0.5350 - consonant_recall: 0.7299 - val_loss: 0.6420 - val_grapheme_loss: 0.3464 - val_vowel_loss: 0.1684 - val_consonant_loss: 0.1272 - val_grapheme_recall: 0.9069 - val_vowel_recall: 0.9787 - val_consonant_recall: 0.9803\n",
      "\n",
      "Epoch 00034: val_grapheme_recall did not improve from 0.91810\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.000743468068680349.\n",
      "666/666 [==============================] - 64s 96ms/step - loss: 3.4798 - grapheme_loss: 2.0147 - vowel_loss: 0.9046 - consonant_loss: 0.5605 - grapheme_recall: 0.3765 - vowel_recall: 0.5360 - consonant_recall: 0.7307 - val_loss: 0.5678 - val_grapheme_loss: 0.3122 - val_vowel_loss: 0.1450 - val_consonant_loss: 0.1107 - val_grapheme_recall: 0.9130 - val_vowel_recall: 0.9793 - val_consonant_recall: 0.9811\n",
      "\n",
      "Epoch 00035: val_grapheme_recall did not improve from 0.91810\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0007297252973710757.\n",
      "666/666 [==============================] - 58s 87ms/step - loss: 3.4771 - grapheme_loss: 2.0105 - vowel_loss: 0.9045 - consonant_loss: 0.5621 - grapheme_recall: 0.3774 - vowel_recall: 0.5366 - consonant_recall: 0.7299 - val_loss: 0.5169 - val_grapheme_loss: 0.2826 - val_vowel_loss: 0.1287 - val_consonant_loss: 0.1055 - val_grapheme_recall: 0.9195 - val_vowel_recall: 0.9811 - val_consonant_recall: 0.9797\n",
      "\n",
      "Epoch 00036: val_grapheme_recall improved from 0.91810 to 0.91954, saving model to ../data/model_weights/resnet18/resnet18_0.9195_64x64_mixup.h5\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.000715760749324711.\n",
      "666/666 [==============================] - 58s 88ms/step - loss: 3.4588 - grapheme_loss: 1.9992 - vowel_loss: 0.9005 - consonant_loss: 0.5591 - grapheme_recall: 0.3799 - vowel_recall: 0.5369 - consonant_recall: 0.7322 - val_loss: 0.5577 - val_grapheme_loss: 0.3078 - val_vowel_loss: 0.1409 - val_consonant_loss: 0.1090 - val_grapheme_recall: 0.9158 - val_vowel_recall: 0.9813 - val_consonant_recall: 0.9817\n",
      "\n",
      "Epoch 00037: val_grapheme_recall did not improve from 0.91954\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007015882058642164.\n",
      "666/666 [==============================] - 58s 88ms/step - loss: 3.4483 - grapheme_loss: 1.9902 - vowel_loss: 0.9012 - consonant_loss: 0.5569 - grapheme_recall: 0.3825 - vowel_recall: 0.5363 - consonant_recall: 0.7324 - val_loss: 0.5634 - val_grapheme_loss: 0.3128 - val_vowel_loss: 0.1424 - val_consonant_loss: 0.1082 - val_grapheme_recall: 0.9133 - val_vowel_recall: 0.9808 - val_consonant_recall: 0.9820\n",
      "\n",
      "Epoch 00038: val_grapheme_recall did not improve from 0.91954\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0006872216535789157.\n",
      "666/666 [==============================] - 60s 90ms/step - loss: 3.4388 - grapheme_loss: 1.9867 - vowel_loss: 0.8964 - consonant_loss: 0.5556 - grapheme_recall: 0.3830 - vowel_recall: 0.5390 - consonant_recall: 0.7321 - val_loss: 0.5283 - val_grapheme_loss: 0.2919 - val_vowel_loss: 0.1325 - val_consonant_loss: 0.1039 - val_grapheme_recall: 0.9202 - val_vowel_recall: 0.9822 - val_consonant_recall: 0.9819\n",
      "\n",
      "Epoch 00039: val_grapheme_recall improved from 0.91954 to 0.92021, saving model to ../data/model_weights/resnet18/resnet18_0.9202_64x64_mixup.h5\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0006726752705214194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 62s 93ms/step - loss: 3.4313 - grapheme_loss: 1.9796 - vowel_loss: 0.8951 - consonant_loss: 0.5566 - grapheme_recall: 0.3843 - vowel_recall: 0.5384 - consonant_recall: 0.7310 - val_loss: 0.5040 - val_grapheme_loss: 0.2842 - val_vowel_loss: 0.1231 - val_consonant_loss: 0.0967 - val_grapheme_recall: 0.9232 - val_vowel_recall: 0.9829 - val_consonant_recall: 0.9823\n",
      "\n",
      "Epoch 00040: val_grapheme_recall improved from 0.92021 to 0.92318, saving model to ../data/model_weights/resnet18/resnet18_0.9232_64x64_mixup.h5\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.000657963412215599.\n",
      "666/666 [==============================] - 62s 93ms/step - loss: 3.4292 - grapheme_loss: 1.9788 - vowel_loss: 0.8947 - consonant_loss: 0.5557 - grapheme_recall: 0.3823 - vowel_recall: 0.5380 - consonant_recall: 0.7323 - val_loss: 0.5332 - val_grapheme_loss: 0.2983 - val_vowel_loss: 0.1322 - val_consonant_loss: 0.1027 - val_grapheme_recall: 0.9165 - val_vowel_recall: 0.9814 - val_consonant_recall: 0.9811\n",
      "\n",
      "Epoch 00041: val_grapheme_recall did not improve from 0.92318\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006431005974894186.\n",
      "666/666 [==============================] - 60s 90ms/step - loss: 3.4106 - grapheme_loss: 1.9644 - vowel_loss: 0.8926 - consonant_loss: 0.5537 - grapheme_recall: 0.3877 - vowel_recall: 0.5397 - consonant_recall: 0.7326 - val_loss: 0.5128 - val_grapheme_loss: 0.2888 - val_vowel_loss: 0.1269 - val_consonant_loss: 0.0972 - val_grapheme_recall: 0.9218 - val_vowel_recall: 0.9815 - val_consonant_recall: 0.9831\n",
      "\n",
      "Epoch 00042: val_grapheme_recall did not improve from 0.92318\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.000628101494146603.\n",
      "666/666 [==============================] - 57s 86ms/step - loss: 3.4024 - grapheme_loss: 1.9609 - vowel_loss: 0.8896 - consonant_loss: 0.5519 - grapheme_recall: 0.3880 - vowel_recall: 0.5403 - consonant_recall: 0.7329 - val_loss: 0.4969 - val_grapheme_loss: 0.2807 - val_vowel_loss: 0.1207 - val_consonant_loss: 0.0955 - val_grapheme_recall: 0.9226 - val_vowel_recall: 0.9826 - val_consonant_recall: 0.9821\n",
      "\n",
      "Epoch 00043: val_grapheme_recall did not improve from 0.92318\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006129809044912887.\n",
      "666/666 [==============================] - 57s 85ms/step - loss: 3.3902 - grapheme_loss: 1.9538 - vowel_loss: 0.8848 - consonant_loss: 0.5515 - grapheme_recall: 0.3895 - vowel_recall: 0.5432 - consonant_recall: 0.7323 - val_loss: 0.4949 - val_grapheme_loss: 0.2779 - val_vowel_loss: 0.1223 - val_consonant_loss: 0.0947 - val_grapheme_recall: 0.9248 - val_vowel_recall: 0.9831 - val_consonant_recall: 0.9821\n",
      "\n",
      "Epoch 00044: val_grapheme_recall improved from 0.92318 to 0.92481, saving model to ../data/model_weights/resnet18/resnet18_0.9248_64x64_mixup.h5\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0005977537507199338.\n",
      "666/666 [==============================] - 62s 93ms/step - loss: 3.3815 - grapheme_loss: 1.9469 - vowel_loss: 0.8847 - consonant_loss: 0.5499 - grapheme_recall: 0.3915 - vowel_recall: 0.5413 - consonant_recall: 0.7356 - val_loss: 0.5741 - val_grapheme_loss: 0.3120 - val_vowel_loss: 0.1515 - val_consonant_loss: 0.1107 - val_grapheme_recall: 0.9172 - val_vowel_recall: 0.9812 - val_consonant_recall: 0.9828\n",
      "\n",
      "Epoch 00045: val_grapheme_recall did not improve from 0.92481\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.0005824350601949143.\n",
      "666/666 [==============================] - 64s 96ms/step - loss: 3.3826 - grapheme_loss: 1.9453 - vowel_loss: 0.8866 - consonant_loss: 0.5507 - grapheme_recall: 0.3892 - vowel_recall: 0.5380 - consonant_recall: 0.7332 - val_loss: 0.5361 - val_grapheme_loss: 0.2940 - val_vowel_loss: 0.1384 - val_consonant_loss: 0.1037 - val_grapheme_recall: 0.9201 - val_vowel_recall: 0.9817 - val_consonant_recall: 0.9825\n",
      "\n",
      "Epoch 00046: val_grapheme_recall did not improve from 0.92481\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.0005670399506143307.\n",
      "666/666 [==============================] - 65s 97ms/step - loss: 3.3580 - grapheme_loss: 1.9308 - vowel_loss: 0.8798 - consonant_loss: 0.5475 - grapheme_recall: 0.3939 - vowel_recall: 0.5431 - consonant_recall: 0.7338 - val_loss: 0.5600 - val_grapheme_loss: 0.3025 - val_vowel_loss: 0.1449 - val_consonant_loss: 0.1126 - val_grapheme_recall: 0.9207 - val_vowel_recall: 0.9819 - val_consonant_recall: 0.9809\n",
      "\n",
      "Epoch 00047: val_grapheme_recall did not improve from 0.92481\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.0005515836150926646.\n",
      "666/666 [==============================] - 64s 95ms/step - loss: 3.3513 - grapheme_loss: 1.9269 - vowel_loss: 0.8779 - consonant_loss: 0.5465 - grapheme_recall: 0.3950 - vowel_recall: 0.5432 - consonant_recall: 0.7358 - val_loss: 0.5154 - val_grapheme_loss: 0.2803 - val_vowel_loss: 0.1343 - val_consonant_loss: 0.1008 - val_grapheme_recall: 0.9260 - val_vowel_recall: 0.9838 - val_consonant_recall: 0.9828\n",
      "\n",
      "Epoch 00048: val_grapheme_recall improved from 0.92481 to 0.92598, saving model to ../data/model_weights/resnet18/resnet18_0.9260_64x64_mixup.h5\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.0005360813071670102.\n",
      "666/666 [==============================] - 64s 96ms/step - loss: 3.3409 - grapheme_loss: 1.9195 - vowel_loss: 0.8766 - consonant_loss: 0.5448 - grapheme_recall: 0.3972 - vowel_recall: 0.5452 - consonant_recall: 0.7362 - val_loss: 0.4854 - val_grapheme_loss: 0.2681 - val_vowel_loss: 0.1229 - val_consonant_loss: 0.0944 - val_grapheme_recall: 0.9287 - val_vowel_recall: 0.9834 - val_consonant_recall: 0.9834\n",
      "\n",
      "Epoch 00049: val_grapheme_recall improved from 0.92598 to 0.92872, saving model to ../data/model_weights/resnet18/resnet18_0.9287_64x64_mixup.h5\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0005205483257436735.\n",
      "666/666 [==============================] - 58s 88ms/step - loss: 3.3357 - grapheme_loss: 1.9157 - vowel_loss: 0.8753 - consonant_loss: 0.5446 - grapheme_recall: 0.3975 - vowel_recall: 0.5445 - consonant_recall: 0.7370 - val_loss: 0.4734 - val_grapheme_loss: 0.2648 - val_vowel_loss: 0.1175 - val_consonant_loss: 0.0910 - val_grapheme_recall: 0.9294 - val_vowel_recall: 0.9834 - val_consonant_recall: 0.9835\n",
      "\n",
      "Epoch 00050: val_grapheme_recall improved from 0.92872 to 0.92935, saving model to ../data/model_weights/resnet18/resnet18_0.9294_64x64_mixup.h5\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.000505.\n",
      "666/666 [==============================] - 63s 95ms/step - loss: 3.3233 - grapheme_loss: 1.9080 - vowel_loss: 0.8726 - consonant_loss: 0.5428 - grapheme_recall: 0.3997 - vowel_recall: 0.5447 - consonant_recall: 0.7376 - val_loss: 0.4807 - val_grapheme_loss: 0.2720 - val_vowel_loss: 0.1179 - val_consonant_loss: 0.0908 - val_grapheme_recall: 0.9235 - val_vowel_recall: 0.9836 - val_consonant_recall: 0.9841\n",
      "\n",
      "Epoch 00051: val_grapheme_recall did not improve from 0.92935\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0004894516742563265.\n",
      "666/666 [==============================] - 57s 85ms/step - loss: 3.3243 - grapheme_loss: 1.9065 - vowel_loss: 0.8743 - consonant_loss: 0.5435 - grapheme_recall: 0.3979 - vowel_recall: 0.5443 - consonant_recall: 0.7371 - val_loss: 0.5494 - val_grapheme_loss: 0.2951 - val_vowel_loss: 0.1463 - val_consonant_loss: 0.1080 - val_grapheme_recall: 0.9246 - val_vowel_recall: 0.9818 - val_consonant_recall: 0.9834\n",
      "\n",
      "Epoch 00052: val_grapheme_recall did not improve from 0.92935\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0004739186928329899.\n",
      "666/666 [==============================] - 58s 88ms/step - loss: 3.3099 - grapheme_loss: 1.8976 - vowel_loss: 0.8702 - consonant_loss: 0.5421 - grapheme_recall: 0.4016 - vowel_recall: 0.5474 - consonant_recall: 0.7369 - val_loss: 0.5162 - val_grapheme_loss: 0.2830 - val_vowel_loss: 0.1318 - val_consonant_loss: 0.1014 - val_grapheme_recall: 0.9273 - val_vowel_recall: 0.9839 - val_consonant_recall: 0.9828\n",
      "\n",
      "Epoch 00053: val_grapheme_recall did not improve from 0.92935\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.00045841638490733545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/666 [======================>.......] - ETA: 12s - loss: 3.2983 - grapheme_loss: 1.8894 - vowel_loss: 0.8699 - consonant_loss: 0.5390 - grapheme_recall: 0.4034 - vowel_recall: 0.5469 - consonant_recall: 0.7391"
     ]
    }
   ],
   "source": [
    "if MODE == 'training':\n",
    "    train_datagen = DataGenerator(df, train_list, generator=train_gen, batch_size=BATCH_SIZE, \n",
    "                                  use_mixup=MIXUP, alpha=ALPHA,\n",
    "                                  use_cutmix=CUTMIX)\n",
    "    valid_datagen = DataGenerator(df, val_list, generator=val_gen, batch_size=BATCH_SIZE)\n",
    "    model.fit_generator(train_datagen,\n",
    "                        steps_per_epoch=len(train_datagen),\n",
    "                        epochs=no_of_epochs,\n",
    "                        validation_data=valid_datagen,\n",
    "                        validation_steps=len(valid_datagen),\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=1,\n",
    "                        initial_epoch=initial_epoch)\n",
    "elif MODE == 'finetune':\n",
    "    train_datagen = DataGenerator(df, list_id, generator=None, batch_size=BATCH_SIZE)\n",
    "    model.fit_generator(train_datagen,\n",
    "                        steps_per_epoch=len(train_datagen),\n",
    "                        epochs=no_of_epochs)\n",
    "    model.save_weights('../data/model_weights/' + model_name + '/' + model_name + '_' + data_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
